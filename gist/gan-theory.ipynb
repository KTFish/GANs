{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs - notes based on [Coursera Course](https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "> :camera: Images used in this gits come from lecture notes to the course [Generative Adversarial Networks (GANs) Specialization](https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans/) on Coursera.\n",
    "\n",
    "A Generative Adversial Network consists of two models. A **discriminator** and a **generator** which compeat with each other.\n",
    "\n",
    "### Discriminator\n",
    "\n",
    "- Task: Grade the generator by evaluating the generated image as fake or real.\n",
    "- Input: Image (generated or real) / Input features X.\n",
    "- Output: Probability of class y (number between 0 and 1).\n",
    "\n",
    "#### Discriminator - details\n",
    "\n",
    "![Alt text](./figures/discriminator-2.png)\n",
    "\n",
    "### Generator\n",
    "\n",
    "- Task: Generate fake images that will look like real ones.\n",
    "- Input: Random noise (random features).\n",
    "- Output: Generated imge.\n",
    "\n",
    "  ![Alt text](./figures/generator-2.png)\n",
    "  ![Alt text](./figures/generator-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCE Cost Function\n",
    "\n",
    "- Measure of how far away from the actual label (0 or 1) is the prediction.\n",
    "- **Close to zero** when the label and the prediciton are **similar** (perfect model would have 0 loss). Approaches **infinity** when the label and the prediciton are **different.**\n",
    "- Output range: between 0 and 1\n",
    "- Used when we want to classify things into two classes (here real and fake images).\n",
    "- For example if the real label is 0 a prediciton 0.98 would be bad and the loss would get high.\n",
    "- Log loss penalizes wrong predictions as well as confident and wrong predicitons.\n",
    "\n",
    "Formula:\n",
    "$$BCE = -\\frac{1}{n}\\sum_{i=1}^n[ (y_i \\log{(p(\\hat{y_i}))} + (1 - y_i)\\log{(1- p( \\hat{y_i}))}]$$\n",
    "$$BCE = -\\frac{1}{n}\\sum_{i=1}^n[ (y_i \\log{(\\hat{y_i})} + (1 - y_i)\\log{(1- \\hat{y_i})}]$$\n",
    "- $y$ - ground truth label (0 or 1).\n",
    "- $\\hat{y}$ - predicted label (between 0 and 1).\n",
    "- $n$ - number of samples.\n",
    "\n",
    "#### Binary Cross Entropy calculation example\n",
    "\n",
    "| i-th sample | Ground truth label $y$ | Predicted label $\\hat{y}$ |\n",
    "| ----------- | ---------------------- | ------------------------- |\n",
    "| 1           | 1                      | 0.9                       |\n",
    "| 2           | 1                      | 0.1                       |\n",
    "| 3           | 0                      | 0.3                       |\n",
    "\n",
    "$BCE = - \\frac{(1 \\cdot \\log{0.9} + (1 - 1)\\cdot \\log{(1- 0.9)} ) + (1 \\cdot \\log{0.1} + (1 - 1)\\cdot \\log{(1- 0.1)} ) + (0 \\cdot \\log{0.3} + (1 - 0)\\cdot \\log{(1 - 0.3)} )}{3} ≈ -\\frac{\\log{(0.9)} + \\log{(0.1)} + \\log{(0.7)}}{3} ≈ - \\frac{-0.105 -2.303 -0.357}{3} = 0.56$\n",
    "\n",
    "Coursera formula:\n",
    "$$J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}logh(x^{(i)}, \\theta) + (1 - y^{(i)})log(1 - h(x^{(i)}, \\theta))]$$\n",
    "\n",
    "$\\theta$ - parameters.\n",
    "$y^{(i)}logh(x^{(i)}, \\theta)$ -\n",
    "$(1 - y^{(i)})log(1 - h(x^{(i)}, \\theta))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Binary Cross Entropy calculation example\n",
    "\n",
    "| i-th sample | Ground truth label $y$ | Predicted label $\\hat{y}$ |\n",
    "| ----------- | ---------------------- | ------------------------- |\n",
    "| 1           | 1                      | 0.9                       |\n",
    "| 2           | 1                      | 0.1                       |\n",
    "| 3           | 0                      | 0.3                       |\n",
    "\n",
    "$BCE = - \\frac{(1 \\cdot \\log{0.9} + (1 - 1)\\cdot \\log{(1- 0.9)} ) + (1 \\cdot \\log{0.1} + (1 - 1)\\cdot \\log{(1- 0.1)} ) + (0 \\cdot \\log{0.3} + (1 - 0)\\cdot \\log{(1 - 0.3)} )}{3} ≈ -\\frac{\\log{(0.9)} + \\log{(0.1)} + \\log{(0.7)}}{3} ≈ - \\frac{-0.105 -2.303 -0.357}{3} = 0.56$\n",
    "\n",
    "Coursera formula:\n",
    "$$J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}logh(x^{(i)}, \\theta) + (1 - y^{(i)})log(1 - h(x^{(i)}, \\theta))]$$\n",
    "\n",
    "$\\theta$ - parameters.\n",
    "$y^{(i)}logh(x^{(i)}, \\theta)$ -\n",
    "$(1 - y^{(i)})log(1 - h(x^{(i)}, \\theta))$\n",
    "\n",
    "![Alt text](./figures/gan-1.png)\n",
    "\n",
    "### Resources to this topic\n",
    "* [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) chapter 4 (logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Challenges | Herausforderungen\n",
    "\n",
    "#### Confusing loss function values :confused:\n",
    "\n",
    "Intuitive the lower is the generators cost function the better should be the generated image. In reality it is not so straight forward. The gerator is graded by the discriminator which improves over time and detects even verry realistic fake images. Sometimes **despite improvment in qualitu of generated images the generators loss function is growing.**\n",
    "\n",
    "#### Hyperparameters\n",
    "\n",
    "There are a lot of hyperparameters in GAN networks. Moreover, GANs are **extremly sensitive** to changes of them. Thats why hyperparameter tuning becomes a challenging task.\n",
    "\n",
    "#### Mode collapse (pol. załamanie trybu)\n",
    "\n",
    "It occurs when the generator finds a **small number of samples** (instead of exploring the whole training data) that succesfuly **fool the discriminator.** In result the generator becomes stuck in a particular pattern, failing to generate diverse images.\n",
    "\n",
    "#### Overcoming challenges :sunglasses:\n",
    "\n",
    "In order to overcome described problems a WGAN or WGAN-GP (Wasserstein GAN Gradient Penalty) archtecture should be consideres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN (Deep Convolutional GAN)\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Gan Archtecture Scheme</b>\n",
    "</font>\n",
    "</summary>\n",
    "<div>\n",
    "<img src = \"layers.png\" width=800>\n",
    "</div>\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "Architecture guidelines for stable Deep Convolutional GANs (cited from [DCGAN paper](https://arxiv.org/abs/1511.06434) )\n",
    "• Replace any pooling layers with strided convolutions (discriminator) and fractional-strided\n",
    "convolutions (generator).\n",
    "• Use batchnorm in both the generator and the discriminator.\n",
    "• Remove fully connected hidden layers for deeper architectures.\n",
    "• Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "• Use LeakyReLU activation in the discriminator for all layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wassersteing GAN\n",
    "\n",
    "> Also called WGAN. It is a **upgrated version of GAN** that introduces another cost function and minimizes the Earth-Mover's distance (EM).\n",
    "\n",
    "### Resources for this topic\n",
    "\n",
    "- [Towards Data Science](https://jonathan-hui.medium.com/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490)\n",
    "\n",
    "### WGAN - Pros and Cons\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <table style=\"display: inline-block;\">\n",
    "    <tr style=\"background-color: lightgray;\">\n",
    "      <th>Pros</th>\n",
    "      <th>Cons</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Better stability</td>\n",
    "      <td>Longer training</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Meaningful loss (which is correlated with convergence and quality of samples)</td>\n",
    "      <td>???</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Improved stability</td>\n",
    "        <td>???</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "</div>\n",
    "\n",
    "> [Read-through: Wasserstein GAN](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html) article by Alexander Irpan in order to better understand the math behind WGAN.\n",
    "\n",
    "- Mode Collapse - when the model collapses and generates images of only one class or only specific classes.\n",
    "\n",
    "- Wasserstein Loss - approximates the Earth Mover's Distance\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"image-1.png\" alt=\"Your Image\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "- Critic - it tries to maximize the distance between the real distribution and the fake distribution.\n",
    "- intermediate image -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### BCE Loss vs Wasserstein Loss\n",
    "\n",
    "| BCE Loss                                                                                                                                                          | Wasserstein Loss                                                                                                                            |\n",
    "| ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Discriminator** outputs values between **0 and 1** (classifies fake and real as 0 and 1). This is because of the sigmoid activation function in the last layer. | **Critic** outputs **any number** (scores images with real numbers). It is **not bounded!** There is no sigmoid function in the last layer. |\n",
    "| $-[\\mathbb{E}\\log{(d(x))} + \\mathbb{E}(1 - \\log{(d(g(z)))})]$                                                                                                     | $\\underset{g}{\\min} \\: \\underset{c}{\\max} \\: \\mathbb{E}(c(x)) - \\mathbb{E}(c(g(z)))$                                                        |\n",
    "|                                                                                                                                                                   | Helps with mode collapse and vanishing gradient problem.                                                                                    |\n",
    "| Measures how bad, on average, some observations are being classified by the discriminator, as fake and real.                                                      | Approximates the **Earth Mover's Distance**.                                                                                                |\n",
    "| There is **no special condition**.                                                                                                                                | **Condition:** function needs to be 1-L Continuous $$\\|\\nabla \\text{critic}(\\text{image})\\|_2 \\le 1$$                                       |\n",
    "| Uses $0$ and $1$ as labels.                                                                                                                                       | Uses $1$ and $-1$ as labels.                                                                                                                |\n",
    "\n",
    "### Lipschitz continuity :small_red_triangle:\n",
    "> :bulb: It is a **neccesery restriction for the critic** used in WGAN. The critic have to be a [continuous](https://en.wikipedia.org/wiki/Continuous_function) [function 1-Lipschtiz](https://en.wikipedia.org/wiki/Lipschitz_continuity). \n",
    "\n",
    "Critic is a function which transforms an image into a prediction.\n",
    "\n",
    "Critic is a 1-Lipschtiz function if for any two images $x_1$ and $x_2$:\n",
    "$$\\frac{|C(x_1) - C(x_2)|}{|x_1 - x_2|} \\le 1$$\n",
    "In this formula $|C(x_1) - C(x_2)|$ is the absolute difference between the critics predictions and $x_1 - x_2$ is the difference between pixel values.\n",
    "\n",
    "> :bulb: In other words we **restrict the speed** of the changes in critics predictions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Weight clipping :scissors:\n",
    "\n",
    "### Gradient penalty :tired_face:\n",
    "\n",
    "Calculating the gradient penalty can be broken into two functions: (1) compute the gradient with respect to the images and (2) compute the gradient penalty given the gradient.\n",
    "\n",
    "$$(\\|\\nabla c(\\hat{x}) \\|_2 - 1)^2$$\n",
    "$\\hat{x} = \\epsilon x + ( 1 - \\epsilon) g(z) $\n",
    "$\\hat{x}$ - mixed image.\n",
    "$x$ - real image.\n",
    "$g(z)$ - generated (fake) image.\n",
    "$\\epsilon$ - ??? Small number?\n",
    "$c(\\hat{x})$ - critics score on the mixed image.\n",
    "\n",
    "![Alt text](image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN & Controllable Generation\n",
    "> ⚠️ Conditional GANs **require a labeled dateset!**\n",
    "\n",
    "| Conditional                            | Unconditional                                  |\n",
    "| -------------------------------------- | ---------------------------------------------- |\n",
    "| Examples from the classes you want.    | Examples from random classes.                  |\n",
    "| Training dataset have to be annotated. | Training dataset dosen't need to be annotated. |\n",
    "\n",
    "### ➡️ Generator Input\n",
    "| Component       | Description                                                                            | Carried Task                                   |\n",
    "| --------------- | -------------------------------------------------------------------------------------- | ---------------------------------------------- |\n",
    "| Noise Vector    | One dimensional vector of random numbers.                                              | Providing randomness in the generation proces. |\n",
    "| Class Vector    | One-hot encoded vector telling the model instance from which class should be generated | Controlling the generation process.            |\n",
    "| Combined vector | Noise vector + Class vector                                                            |                                                |\n",
    "\n",
    "> Size of the class vector is equal to the number of classes.\n",
    "\n",
    "### ➡️ Discriminator Input\n",
    "> The classes are passed to the discriminator as on-hot matrices.\n",
    "\n",
    "## Controllable Generation vs, Conditional Generation\n",
    "|Compared Feature| Controllable | Conditional |\n",
    "|----| ------------ | ----------- |\n",
    "|Examples| Examples with the features you desire. | Examples of the classes you desire. |\n",
    "| Training dataset| Training dataset dosen't need to be annotated. | Training dataset have to be annotated. |\n",
    "|| Manipulate the z vector input. | Append a class vector to the input. |\n",
    "|⚠️Challanges | When trying to control one feature, others that are correlated might change.| |\n",
    "\n",
    "> ⚠️ It is not possible to control **single** output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose Convolution `torch.nn.ConvTranspose2d`\n",
    "> ⚠️ The name can be confussig. There is no transpose or real convolution used.\n",
    "> A good explanation of this by [Shubham Singh](https://www.youtube.com/watch?v=U3C8l6w-wn0) on YouTube.\n",
    "\n",
    "* Transpose convolution means to scalar-multiply a kernel by each pixel in an image.\n",
    "* The dimensions of the result tensor of transpose convolution is greater than the source dimensions.\n",
    "* It is used to upscale images.\n",
    "* Takes the same parameters as standard convolution: `kernel_size`, `padding` and `stride`.\n",
    "\n",
    "$$N_h = s_h(M_h - 1) + k - 2p$$\n",
    "Where:\n",
    "- $N_h$ - Number of pixels in output image.\n",
    "- $M_h$ - Number of pixels in input image.\n",
    "- $s_h$ - Stride (skipping parameter). \n",
    "- $p$ - Padding.\n",
    "- $k$ - Kernel size.\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Visual Example of Transpose Convolution</b>\n",
    "</font>\n",
    "</summary>\n",
    "<img src=\".\\figures\\transpose.png\">\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# OTHER\n",
    "\n",
    "# Glossary\n",
    "\n",
    "- GAN -\n",
    "- Discriminator - Minimizes cost\n",
    "- Generator - Maximizes cost\n",
    "- BCE Loss - essentially measures how bad, on average, some observations are being classified by the discriminator, as fake and real.\n",
    "  Real / Fake Distribution -\n",
    "- Earth Mover's Distance - its a measure of **how different two distributions are** by estimating the effort it takes to make the generated distribution equal to the real one.\n",
    "- Vanishing Gradient Problem -\n",
    "\n",
    "\n",
    "\n",
    "# Practical notes\n",
    "\n",
    "- Nice functions for creatning blocks of the neural network latter used in the class implementation as a layer.\n",
    "- The magnitude of a gradient is also called the norm.\n",
    "\n",
    "### Problems\n",
    "\n",
    "- I didn't really understood how the gradient in Wasserstein GAN is calculated.\n",
    "\n",
    "---\n",
    "\n",
    "### Questions\n",
    "\n",
    "> **What is the primary goal of the discriminator, in a probabilistic sense?**\n",
    "> The discriminator finds the probability of class y (real or fake) given input features x.\n",
    "\n",
    "> **What is the primary goal of the generator, in a probabilistic sense?**\n",
    "> Model the features x conditioned on class y: P( x | y ).\n",
    "\n",
    "> **How does the discriminator learn over time?**\n",
    "> Getting feedback on if its classification was correct.\n",
    "\n",
    "- What should the skill levels of the discriminator and generator be? - Both should be at similar skill levels.\n",
    "- What is the difference between upsampling and transposed convolution layers? - Upsampling infers pixels using a predefined method, while transposed convolution learns a filter\n",
    "- What do the discriminator and critic have in common? - They both want to maximize the difference between the expected values of the predictions for real and fake.\n",
    "- What points on a function are considered for the evaluation of 1-Lipschitz continuity? -\n",
    "  All points on the function. The slope can not be greater than 1 at any point on a function in order for it to be 1-Lipschitz Continuous.\n",
    "- When is a function 1-Lipschitz Continuous? -\n",
    "  When its gradient norm is less than or equal to 1 at all points.\n",
    "- Why do you use an intermediate image for calculating the gradient penalty? - Since checking the critic’s gradient at each possible point of the feature space is virtually impossible, you can approximate this by using interpolated images.\n",
    "- What is a soft way to restrict the critic to be 1-Lipschitz? -\n",
    "  Adding a regularization term for the weights, as in L2 norm/regularization. By using a gradient penalty, you are not strictly enforcing 1-L continuity, but encouraging it\n",
    "> **How does the generator learn what class to generate (in Condiditional GANs)?**\n",
    "> The discriminator is checking if an image looks real or fake based on (conditioned on) a certain class.\n",
    "\n",
    "> **How is adding the class information different for the discriminator and generator, and why (in Condiditional GANs)?**\n",
    "> For the discriminator, the class information is appended as a channel or some other method, whereas for the generator, the class is encoded by appending a one-hot vector to the noise to form a long vector input.\n",
    "\n",
    "> **What is a key difference between controllable generation and conditional generation?**\n",
    "> Controllable generation is done after training by modifying the z vectors passed to the generator while conditional generation is done during training and requires a labelled dataset.\n",
    "\n",
    "> **How are controllable generation and interpolation similar?**\n",
    "> They both change features by adapting values of the z vector.\n",
    "\n",
    "> **When does controllable generation commonly fail?**\n",
    "> When features strongly correlate with each other and z values don’t correspond to clear mappings on their images.\n",
    "\n",
    "> **How can you use a classifier for controllable generation?**\n",
    "> You can calculate the gradient of the z vectors along certain features through the classifier to find the direction to move the z vectors.\n",
    "\n",
    "> **What is the purpose of disentangling models?**\n",
    "> To correspond values in a z vector to meaningful features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Resources\n",
    "\n",
    "### You Tube\n",
    "- [Practical GAN YouTube tutorials](https://www.youtube.com/watch?v=OXWvrRLzEaU&list=PLhhyoLH6IjfwIp8bZnzX8QR30TRcHO8Va) by \n",
    "Aladdin Perss\n",
    "- [WGAN implementation from scratch (with gradient penalty)](https://www.youtube.com/watch?v=pG0QZ7OddX4)\n",
    "- Understand [Transpose convolution](https://www.youtube.com/watch?v=U3C8l6w-wn0) by Shubham Singh - theory explanation and Python implementation.\n",
    "\n",
    "### Papers\n",
    "\n",
    "- Interactive paper [Deconvolution and Checkerboard Artifacts](https://distill.pub/2016/deconv-checkerboard/)\n",
    "- [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "# Ideas\n",
    "\n",
    "- Easy GAN project (MINST or something at similar difficulty level) max 4h of work.\n",
    "- Fast SQL task during breaks\n",
    "- The course exercise notebooks are well structured. It is agood place to take inspiration for my own project and/or Czarna Magia Bootcamp.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
