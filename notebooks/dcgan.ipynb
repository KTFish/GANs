{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Deep Convolutional GAN\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KTFish/DCGAN/blob/main/dcgan.ipynb)\n",
    "\n",
    "Deep Convolutional Generative Adversarial Network architecture implementation. Today the usage of convolution in GANs is a standard and according to [Generative Deep Learning. Teaching Machines to Paint, Write, Compose, and Play](https://helion.pl/ksiazki/generative-deep-learning-teaching-machines-to-paint-write-compose-and-play-david-foster,e_16sj.htm#format/e) usually when we say GAN we really think about a DCGAN.\n",
    "\n",
    "### Some resources related to this topic\n",
    "\n",
    "- DCGAN [paper](https://arxiv.org/abs/1511.06434).\n",
    "- [Papers with Code](https://paperswithcode.com/method/dcgan) explanation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make sure the Colab Button works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(42) \n",
    "# Import helper functions\n",
    "# from scripts.utils import get_random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim: int, img_channels: int, hidden_units: int) -> None:\n",
    "        \"\"\"Generator model.\n",
    "\n",
    "        Args:\n",
    "            z_dim (int): Dimension of the noise vector used for image generation.\n",
    "            img_channels (int): Number of channels in the generated image.\n",
    "            hidden_units (int): Number of neurons in the hidden layer.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self._generator_block(\n",
    "                in_channels=z_dim,\n",
    "                out_channels=hidden_units * 4,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),  # First generator block\n",
    "            # Rest of the generator blocks...\n",
    "            self._generator_block(\n",
    "                in_channels=hidden_units * 4, out_channels=hidden_units * 2\n",
    "            ),\n",
    "            self._generator_block(\n",
    "                in_channels=hidden_units * 2, out_channels=hidden_units\n",
    "            ),\n",
    "            self._generator_final_block(hidden_units, img_channels),  # Final block\n",
    "        )\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    def _generator_block(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 4,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Creates a single generator block.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int, optional): Size of convolution filter. Defaults to 4.\n",
    "            stride (int, optional): Stride size. Defaults to 2.\n",
    "            padding (int, optional): Amount of pixels added around the image. Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Returns a tensor with performed convolutions.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def _generator_final_block(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 4,\n",
    "        stride: int = 2,\n",
    "        padding: int = 1,\n",
    "    ) -> torch.Tensor:\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )  # Output range: [-1, 1]\n",
    "\n",
    "    def forward(self, noise: torch.Tensor) -> torch.Tensor:\n",
    "        x = noise.view(len(noise), self.z_dim, 1, 1)\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels, hidden_units) -> None:\n",
    "        \"\"\"Discriminator model for DCGAN architecture based\n",
    "         on Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks paper.\n",
    "         Paper: https://arxiv.org/abs/1511.06434\n",
    "\n",
    "        Args:\n",
    "            img_channels (int): Number of channels of the image (for example for RGB its 3).\n",
    "            hidden_units (int): Number of neurons in hidden layer.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self._block(img_channels, hidden_units, kernel_size=4, stride=2, padding=1),\n",
    "            self._block(hidden_units, hidden_units * 2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units * 2,\n",
    "                out_channels=1,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.Sigmoid(),  # Output range [0, 1]\n",
    "        )\n",
    "\n",
    "    def _block(\n",
    "        self, in_channels, out_channels, kernel_size=4, stride=2, padding=1\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Creates a single discriminator block consisting of a convolution layer, batch normalization and Leaky ReLU.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "                out_channels (int): Number of output channels.\n",
    "                kernel_size (int, optional): Size of convolution filter. Defaults to 4.\n",
    "                stride (int, optional): Stride size. Defaults to 2.\n",
    "                padding (int, optional): Amount of pixels added around the image. Defaults to 1.\n",
    "        Returns:\n",
    "            torch.Tensor: Returns a tensor with performed convolutions.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Foward pass implementation for the discriminator.\n",
    "\n",
    "        Args:\n",
    "            image (torch.Tensor): Flattened tensor representing an image.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        predicitons = self.disc(image)\n",
    "        return predicitons.view(len(predicitons), -1) # Reshape to one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_noise(n_samples: int, z_dim: int, device: str = \"cpu\") -> torch.Tensor:\n",
    "    \"\"\"Returns a noise vector z (used by the generator to create an image).\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): Number of samples that will be generated from that vector. Usually set to batch size.\n",
    "        z_dim (int): Dimension of the noise vector.\n",
    "        device (str, optional): Device on which the vector will be stored. Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Noise.\n",
    "    \"\"\"\n",
    "    return torch.randn(n_samples, z_dim, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 16\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "z_dim = 64\n",
    "display_step = 100\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "betas=(0.5,0.999)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.05,))\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=MNIST('dataset', download=True, transform=transform),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "gen = Generator(z_dim, img_channels=1, hidden_units=hidden_units).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "disc = Discriminator(img_channels=1, hidden_units=hidden_units).to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=betas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_weights(model: nn.Module) -> None:\n",
    "    \"\"\"Initializes weights using a normal distribution with mean 0 and std 0.02.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The generator or discriminator model.\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        # if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weights_initialization() -> None:\n",
    "    \"\"\"Tests the initialize_weights() function\"\"\"\n",
    "    N, C, H, W = 8, 3, 64, 64\n",
    "    z_dim = 100\n",
    "\n",
    "    x = torch.randn(\n",
    "        (N, C, H, W)\n",
    "    )  # Simulate a random batch of images of shape N x C x H x W\n",
    "\n",
    "    ### Test Discriminator\n",
    "    disc = Discriminator(img_channels=C, hidden_units=8)\n",
    "    initialize_weights(model=disc)\n",
    "\n",
    "    # There should be outputet one prediction per image\n",
    "    assert disc(x).shape == (N, 1, 1, 1), \"Discriminators weights are not initialized correctly.\"\n",
    "\n",
    "    ### Test Generator\n",
    "    gen = Generator(z_dim=z_dim, img_channels=C, hidden_units=8)\n",
    "    initialize_weights(model=gen)\n",
    "    \n",
    "    noise = torch.randn((N, z_dim, 1, 1))\n",
    "    fake_image = gen(noise)\n",
    "    \n",
    "    assert fake_image.shape == (\n",
    "        N,\n",
    "        C,\n",
    "        H,\n",
    "        W,\n",
    "    ), f\"Generators weights are not initialized correctly. Instead of ({N}, {C}, {H}, {W}) they are {fake_image.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the batches\n",
    "    for real, _ in dataloader:\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "\n",
    "        ## Update discriminator ##\n",
    "        disc_opt.zero_grad()\n",
    "        fake_noise = get_random_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake = gen(fake_noise)\n",
    "        disc_fake_pred = disc(fake.detach())\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_pred = disc(real)\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "        # Update gradients\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        # Update optimizer\n",
    "        disc_opt.step()\n",
    "\n",
    "        ## Update generator ##\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_random_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        disc_fake_pred = disc(fake_2)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ## Visualization code ##\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
